Starting Training Loop...
Epoch 1/10
/anaconda/envs/py38_default/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/anaconda/envs/py38_default/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/anaconda/envs/py38_default/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
Validation Loss: 8.4296, Validation BLEU: 0.0000, Validation METEOR: 0.0599
0m 2s (- 0m 0s) (50 100%) 0.0997
Epoch 2/10
Traceback (most recent call last):
  File "/home/xnmaster/XNAPproject-grup-04/TrainMar.py", line 256, in <module>
    main()
  File "/home/xnmaster/XNAPproject-grup-04/TrainMar.py", line 253, in main
    trainIters(encoder1, attn_decoder1, int(args.epochs), train_pairs, val_pairs, print_every=5000, learning_rate=float(args.lr))
  File "/home/xnmaster/XNAPproject-grup-04/TrainMar.py", line 184, in trainIters
    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)
  File "/home/xnmaster/XNAPproject-grup-04/TrainMar.py", line 85, in train
    loss.backward()
  File "/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/anaconda/envs/py38_default/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: cudnn RNN backward can only be called in training mode