
En la primera sessió ens em plantejat diverses preguntes:

1. Afecta el volum de dades que tenim al entrenament?
2. Quines diferències de rendiment hi ha entre l'ús de LSTM i GRU en un model Seq2Seq per a la traducció automàtica?
3. Quin impacte tenen les tècniques de regularització, com ara el dropout o la normalització de pes, en la capacitat del model per generalitzar i evitar el sobreajustament?
4. Com afecta l'elecció de la dimensionalitat de les representacions vectorials (embeddings) de les paraules al rendiment del model en termes de precisió i capacitat de generalització?
